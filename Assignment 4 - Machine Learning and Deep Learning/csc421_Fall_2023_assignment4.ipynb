{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Fall 2023 Assignment 4 \n",
    "### Author: George Tzanetakis \n",
    "\n",
    "This notebook is based on the topics covered in **Chapter 18 Learning ** and **Chapter 21 Deep Learning from the book *Artificial Intelligence: A Modern Approach.*  You are welcome and actually it can be educational to look at the code at the aima-code repository as well as other code resources you can find on the web. However, make sure you understand any code that you incoporate. \n",
    "\n",
    "The assignment structure is as follows - each item is worth 1 point: \n",
    "\n",
    "1. Create mini CIFAR-10 (Basic)   \n",
    "2. SVM classification of CIFAR-10 (Basic) \n",
    "3. Naive Bayes Gaussian (Expected) \n",
    "4. Sort classes by prediction accuracy (Basic) \n",
    "5. Show misclassification examples (Expected) \n",
    "6. Compare raw image, histogram-of-gradients, and principal component analysis of hogs (Expected)\n",
    "7. Change batch size and optimizer and compare (Basic) \n",
    "8. Add noise to test images (Expected)  \n",
    "9. Generate synthetic dataset (4 colors, 4 shapes, 4 sizes, 4 x positions, 4 y positions) (Advanced)\n",
    "10. Deep learning classification of synthetic dataset (Advanced) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (Basic) Create mini CIFAR-10 \n",
    "\n",
    "Re-use the code from the deep learning notebook to load the CIFAR-10 training and test datasets. \n",
    "Create a mini CIFAR-10 dataset with 5000 instances for training and 5000 instances for testing. \n",
    "The examples in CIFAR-10 are randomly shuffled so you can simply take the first 5000 examples of each dataset. Print the shape of the resulting training set and test set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here \n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "trainset.data = trainset.data[:5000]\n",
    "trainset.targets = trainset.targets[:5000]\n",
    "testset.data = testset.data[:5000]\n",
    "testset.targets = testset.targets[:5000]\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (Basic)  - SVM  \n",
    "\n",
    "Train a SVM classifier on PCA dimensionality reduced Histogram of Oriented Gradients features. You can re-use the code from the deep learning notebook but instead of using the full training and testing sets use the mini-CIFAR-10 datset you created in question 1. Report the classification accuracy and confusion matrix. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Your code goes here \n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "def pca_hog_extract(X):\n",
    "    X_hog = []\n",
    "    for i in range(len(X)):\n",
    "        fd  = hog(X[i] , orientations=9 , pixels_per_cell = (8,8),\n",
    "                     cells_per_block = (2,2) , visualize = False, channel_axis=-1)\n",
    "    X_hog.append(fd)\n",
    "\n",
    "    X_hog = np.array(X_hog)\n",
    "    print(X_hog.shape)\n",
    "    pca = PCA(n_components=0.8)\n",
    "    X_pca = pca.fit_transform(X_hog)\n",
    "    return X_pca\n",
    "\n",
    "X_train = pca_hog_extract(trainset.data)\n",
    "X_test = pca_hog_extract(testset.data)\n",
    "\n",
    " \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (Expected) - Gaussian Naive Bayes Classifier \n",
    "\n",
    "Repeat the training and evaluation of the mini-CIFAR-10 dataset using the Gaussian Naive Bayes \n",
    "classifier from scikit-learn: [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "Similarly report on the classification accuracy and confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Question 4 (Expected) - Sort classes by prediction accuracy \n",
    " \n",
    "Write a function that takes as input the computed confusion matrix and returns a list of classes sorted by classification accuracy. Each item in the list should be a tuple of the form (class, accuracy). Show the outpput for the SVM and Gaussian NB classifiers for the mini CIFAR-10 dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (Expected) - Show misclassification examples  \n",
    "\n",
    "Write a function that takes as input a particular class (for example dog) and shows an array \n",
    "of images (similar to the functions showing images in the deep learning notebook) in which each row contains 10 example images from another class that were misclassified. The resulting grid will have 9 rows (one for each class other than the input class) and 10 examples. For example the row for truck would have images of trucks that were misclassified as dogs. Show the output of this function for the SVM classifier and the class horse. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 (Expected) - Comparison of different features \n",
    "\n",
    "In the deep learning notebook the CIFAR-10 classification code using SVM utilizes a histogram of oriented gradients features followed by a PCA transformation for dimensionality reduction. \n",
    "Using the mini-CIFAR-10 dataset compare the following three feature front-ends using SVM classificaiton (use the same parameters as the deep learning notebook): \n",
    "\n",
    "1. Flatten the training images to a single (32 * 32 * 3) vector\n",
    "2. Compute the Histogram of Gradients\n",
    "3. Computer the Histogram of Gradients followed by PCA (as done in the deep learning notebook).\n",
    "\n",
    "Compare these three feature front ends by showing the corresponding classification accurarcy and confusion matrices for each one. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 7 (Basic) - Deep learning classification  \n",
    "\n",
    "Retrain the deep neural network specified in the deep learning notebook. You will need to install PyTorch for your system. You don't need to use the GPU unless you have one and can set it up. \n",
    "Your training time will depend on your hardware on my laptop with CPU it takes about 4 minutes and with GPU about 2 minutes. It should not be more than 30 minutes even on an old slow laptop. Another option is to use Google Colab. \n",
    "\n",
    "Once you have trained and evaluated the network and got numbers similar to the deep learning notebook change the batch size to 16. Repeat the training and report on how the accuracy and training time changed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 8 (EXPECTED) - Deep learning classification of noisy images\n",
    "\n",
    "In this question you will explore the effect of adding noise to the classification of the CIFAR-10 dataset. You can add random noise with a mean of 0 and standard deviation of 1 to a tensor using the *torch.randn*. For example: x = x + torch.randn(x.shape) will add noise to the tensor x. \n",
    "Add noise with a mean of 0 and a standard deviation of 0.2 to the images of the CIFAR-10 dataset. First see how the images with the added noise will look by adding the noise in the *imshow* function. Then check how the classification accuracy on the test set is affected if you add noise to the test but NOT the training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 9 (ADVANCED) - Synthetic generation of dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is a bit more open ended, will require some creativity and extra work. \n",
    "Your goal is to generate a synthetic dataset of shapes. Below is some code for generating \n",
    "some shapes with matplotlib. Your code should generate random shape using uniform random distributions along the following \"dimensions\": shape (square, circle, triangle, rhombus), \n",
    "color (red, green, blue, yellow, orange, black), size (continuous but should fit in the image), \n",
    "x-position (continuous but should fit in the image), y_position (continuous but should fit in the image). Once you create a plot you will need to figure out how to convert it to an image. All your images should be 64 by 64 which is bigger than the CIFAR-10 images. Generate a dataset that has 6000 instances of each shape, and 1000 instances of each color within each shape. Show some sample images by appropriately calling/modifying if needed the imshow() function from the deep learning notebook. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon, Circle, Rectangle\n",
    "\n",
    "red, blue, yellow, green = '#ff0000', '#0000ff', '#ffff00', '#00ff00'\n",
    "square = Rectangle((0.7, 0.1), 0.25, 0.25, facecolor=red)\n",
    "circle = Circle((0.8, 0.8), 0.15, facecolor=blue)\n",
    "triangle = Polygon(((0.05,0.1), (0.396,0.1), (0.223, 0.38)), fc=yellow)\n",
    "rhombus = Polygon(((0.5,0.2), (0.7,0.525), (0.5,0.85), (0.3,0.525)),  fc=green)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, facecolor='k', aspect='equal')\n",
    "for shape in (square, circle, triangle, rhombus):\n",
    "    ax.add_artist(shape)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 10 (ADVANCED) - Deep learning for the synthetic shapes \n",
    "\n",
    "Using the deep learning notebook code as a template build a traditional machine learning classifier using Histogram-of-Oriented Gradients features followed by PCA and using a SVM as a classifier. Train classifiers for the following 3 problems: classify shape (irrespective of color), classify color (irrespective of shape), or classify both color and shape (you can train two SVMs one for each problem). Then repeat the same three configurations using a deep learning neural network. \n",
    "Report on the classification accuracy and confusion matrices for all 6 configurations (shape-SVM, color-SVM, shape+color SVM, shape-DNN, color-DNN, shape+color DNN). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
